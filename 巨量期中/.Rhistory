(x == 0) & (x <- x + 1)
(x == 0) & (x <- x + 1)
(x == 0) && (x <- x + 1)
(x == 0) && (x <- x + 1)
(x == 0) || (x <- x + 1)
(x == 4) || (x <- x + 1)
(x == 4) || (x <- x + 1)
rm(ls())
rm(list = ls())
# %in%
'a' %in% letters
letters
# %in%
'a' %in% letters
c('a', 'b', '1') %in% letters
# Package::function() or Package::object
a = 1:5
mean = function(x) print("a function called \"mean\" ")
mean(a)
base::mean(a)
x = 3
is.vector(x)
is.numeric(x)
is.integer(x)
####################
#### Unit 2 R codes
####################
rm(list = ls())
x = 3
is.vector(3)
x = 3
is.vector(3) # R 最小單位 : vector
typeof(x)
mean(x = 1:10) # "=" is used as a function argument binding
mean(x <- 1:10) # "<-" is used as a variable assignment
mean(x = 1:10) # "=" is used as a function argument binding ( mean 的參數 x 為 1 : 10)
mean(x <- 1:10) # "<-" is used as a variable assignment (將 1 : 10 存入變數 x，並傳給 mean 的參數 x)
mean(x = x <- 1:10)
mean(x = x = 1:10) # "=" is used as a function argument binding ( mean 的參數 x 為 1 : 10)
mean(x = x <- 1:10)
v3 = vector(mode="character", length= 3)
v4 = vector(mode="logical", length= 2)
a = array(c(1,2,3,4,5,6), dim=c(1,2,3)) # 1 by 2 by 3
a
a = array(c(1,2,3,4,5,6), dim=c(1,2,3)) # 1 by 2 by 3
a
dim(a) # get the dimension of the array
dim(a) # get the dimension of the array
dim(a) # get the dimension of the array
v1 = c(9,8,7)
v2 = c("a","b","c")
#combine 2 vectors
d = data.frame(x1 = v1, x2 = v2, stringsAsFactors = F)
View(d)
str(d) # show the structure of the data frame “d”
# Using package "data.table"
library(data.table)
d_dt = data.table(d)
str(d_dt) # "data.table" is also a kind of data frame
# key-value pairs of data
L = list(k1 = c(9, 8, 7), k2 = c("a","b","c"), k3 = c(1))
L[1:2]
L
data.frame(L)
L$k1  # get the data in the list L with the key “k1”
L$k3
# 常用來表示 ordinal、nominal 變數
group = c("control", "treatment", "treatment", "control")
group
group_f = factor(group, levels=c("treatment", "control"))
group_f  # check the actual data type of “group_f”
typeof(group_f)
unclass(group_f) # remove class attributes to get real data values
unclass(group_f) # remove class attributes to get real data values
smoker = as.data.frame(smoker)
library('bigDataR')
library('bigDataR')
####################
#### Unit 2 R codes
####################
rm(list = ls())
library('bigDataR')
install.packages('bigDataR')
library('bigDataR')
library('bigDataR')
library('bigDataR')
a = c(1,2,3,4)
a
is.vector(a)
is.matrix(a)
m = as.matrix(a)
m
is.matrix(m)
t(m) # transpose the matrix
a
is.matrix(a)
m = as.matrix(a, byrow = T)
m
m = as.matrix(a, nrow = 1)
m
m = as.matrix(a, ncol = 4)
m
a = c(1,2,3,4)
m = as.matrix(a, ncol = 4)
m
a = c(1,2,3,4)
a
is.vector(a)
is.matrix(a)
m = as.matrix(a, ncol = 4)
m
is.matrix(m)
t(m) # transpose the matrix
m = as.matrix(a, ncol = 4, nrow = 1)
m
m = as.matrix(a, ncol = 2, nrow = 2)
m
a = c(1,2,3,4)
a
is.vector(a)
is.matrix(a)
m = as.matrix(a, ncol = 2, nrow = 2)
m
is.matrix(m)
t(m) # transpose the matrix
m = as.matrix(1:4, ncol = 2, nrow = 2)
m
m = as.matrix(1:4, ncol = 2, nrow = 2,byrow = T)
m
m = matrix(1:4, ncol = 2, nrow = 2,byrow = T)
m
m = matrix(a, nrow = 1,byrow = T)
m
m = as.matrix(a)
m
is.matrix(m)
t(m) # transpose the matrix
a = NA ; typeof(a)
a = NA ; typeof(a)
# NA : 存在但遺失，佔記憶體空間
a = NA ; typeof(a)
object.size(a) # get the object size (bytes) in memory
# NULL : 不存在，不佔記憶體空間
b = NULL; typeof(b)
object.size(b)
square = function(x = NULL){
return(ifelse(is.null(x), "NULL", x^2 ) );
}
# if x is not NULL, then output x squared.
square()
square(3)
x = 'global'
printXY = function(){
y = 'local';
print(x);
print(y);
}
printXY()
x
y
# assign a new string to x then print
x = 'global_x'
printX = function(x){
print(x); x = 'local_x'; print(x);
}
printX(x)
# Set operations, an R ellipsis example
setOper = function(f, ...){
el = list(...)
return(Reduce(f, el))
}
setOper(intersect, 1:5, 2:6, 3:5)
setOper(union, 1:5, 2:6, 3:5)
setOper(intersect, 1:5, 2:6, 3:5)
# Set operations, an R ellipsis example
setOper = function(f, ...){
print(..3)
el = list(...)
return(Reduce(f, el))
}
setOper(intersect, 1:5, 2:6, 3:5)
# A example of function factory
powFunc = function(n){
return(function(k) k^n)
}
square = powFunc(2)
square(3)
cube = powFunc(3)
cube(2)
powFunc(5)(2)
f = function(x){
if(x > 10){
print("x is great than 10");
} else if( x >=0 & x <=10) {
print("x is between 0 and 10");
} else {
print("x is less than 0");
}
}
f(-1)
f(5)
f(11)
library(ggplot2movies)
movies = as.data.frame(movies); movies$longshort = ""
View(movies)
movies$length > 120
# Very bad practice with for loop. Don't do this!
system.time({
for(i in 1:nrow(movies)){
if(movies[i, "length"] > 120) movies[i, "longshort"] = "long"
else movies[i, "longshort"] = "short" }
})
# Use ifelse() instead
system.time(
movies$longshort <- ifelse(movies$length > 120, "long", "short"))
# Or simply vectorized it!
system.time({
movies[movies$length > 120, "longshort"] = "long"
movies[movies$length <= 120, "longshort"] = "short"
})
for(i in c('a','b')) print(i)
for(k in 1:3) {
if(k == 3) break; print(k);
}
x = 3;
while(x > 0){
print(x);
x = x - 1;
}
switch(3, 'a' = {x = x + 5;},
'b' = {x = 999},'c' = {x = 'ABC'}
)
x # 2nd statement after expr
bmi_num = c(19,39,20,22,34,24);
bmi_cat = cut(x=bmi_num,breaks=c(0,18.5,24.9, 29.9, Inf),
labels=c('Underweight','Normal weight','Overweight','Obesity'));
bmi_cut_str = "lo:18.5 = 'Underweight';
18.5:24.9 = 'Normal weight';
24.9:29.9 = 'Overweight';
29.9:hi = 'Obesity'"
bmi_cat = car::recode(bmi_num, bmi_cut_str, as.factor = T,
levels = c('Underweight','Normal weight','Overweight','Obesity'))
table(bmi_cat)
xtabs(~ bmi_cat,  bmi_cat)
xtabs(~ bmi_cat)
xtabs(~ bmi_cat)
table(bmi_cat)
write.csv(as.data.frame(matrix(runif(10 ^ 6 ,0,1),  nrow=1000)), file='rnum.csv');
write.csv(as.data.frame(matrix(runif(10 ^ 6 ,0,1),  nrow=1000)), file='rnum.csv');
# An ~18 MB CSV file.
file.info("rnum.csv")$size; # get file size
system.time({rnum = read.csv(file= "rnum.csv", header=T)});
rm(rnum); library("data.table"); #load package data.table
system.time({ rnum = fread(input="rnum.csv")});
rm(rnum); library("sqldf"); # load package sqldf
system.time({ rnum = read.csv2.sql(file="rnum.csv", header=T,sep = ",");})
rm(rnum); library("sqldf"); # load package sqldf
system.time({ rnum = read.csv2.sql(file="rnum.csv", header=T,sep = ",");})
rm(rnum); library("data.table"); #load package data.table
system.time({ rnum = fread(input="rnum.csv")});
rm(rnum); library("data.table"); #load package data.table
system.time({ rnum = fread(input="rnum.csv")});
rm(rnum); library("sqldf"); # load package sqldf
system.time({ rnum = read.csv2.sql(file="rnum.csv", header=T,sep = ",");})
# rank by "mpg“ & create a new dataset
data.frame("car_name" = rownames(mtcars),
"mpg" = mtcars$mpg,
"rank" = rank(mtcars$mpg, ties.method = "first"))
rownames(mtcars)
mtcars
# rank by "mpg“ & create a new dataset
data.frame("car_name" = rownames(mtcars),
"mpg" = mtcars$mpg,
"rank" = rank(mtcars$mpg, ties.method = "first"))
# Pearson’s Correlation 是對連續並符合常態假設的資料進行相關分析的方法。
# Spearman’s Rank Correlation 是對連續但"不"符合常態假設的資料進行相關分析的方法。
# p value < 0.05, bmi and age are correlated
cor.test(insurance$bmi, insurance$age, method = "pearson")
cor.test(insurance$bmi, insurance$age, method = "spearman")
setwd("~/GitHub/bigdata_team_project/巨量期中")
# setwd("~/GitHub/bigdata_team_project/巨量期中")
rm(list=ls()) # clean env
pacman::p_load("data.table", "tidyverse", "sqldf", "jsonlite", "corrplot", "d3heatmap") # load packages
load("./pre_process.rdata") # load pre process data : youtube and mostViews
# channel of most frequently appearing in trending videos : 前 10 最常上熱門的頻道
group_by(youtube, channel_title) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(10) %>% ggplot(aes(x = reorder(channel_title, n), y = n, fill = channel_title)) + geom_bar(stat = "identity") + coord_flip()
# video publish time : 下午 4 點左右為影片發布熱點
mutate(youtube, hour = hour(publish_time)) %>% group_by(hour) %>% summarise(n = n()) %>% ggplot(aes(x = hour, y = n)) + geom_line() + scale_x_continuous(breaks=c(0:23)) + labs(x = "hour", y = "number of videos") + geom_vline(xintercept = 16 , color = "#ff2244", size = 1)
# Number of videos by weekdays : 週五、週四影片發布量最多
mutate(youtube, weekday = weekdays(publish_time)) %>% group_by(weekday) %>% summarise(n = n()) %>% ggplot(aes(x = reorder(weekday, n), y = n, fill = weekday)) + geom_bar(stat = "identity") + labs(y = "number of videos")
# videos published heat map : 每周二到四下午四點左右為影片發布熱點, Sunday is 0.
table(format(youtube$publish_time,"%H"), format(youtube$publish_time,"%w")) %>% as.data.frame.matrix %>% d3heatmap(F, F, col = colorRamp(c("seagreen", "lightyellow", "red")))
mostViews = mutate(mostViews, time = format(publish_time, "%Y-%m"))
group_by(mostViews, category, time) %>% summarise(n = n()) %>% ggplot(aes(x = time, y = n, group = category, color = category)) + geom_line() + xlim("2017-11", "2017-12", "2018-01") + theme(axis.text.x = element_text(angle = 90))
paste(a, 1)
paste("a", 1)
paste("a", 1, swp = "")
paste("a", 1, sep = "")
paste("2017", c(11, 12))
paste("2017-", c(11, 12))
paste("2018-", c(1:6), sep ="")
breaks = paste("2017-", c(11, 12), sep ="")
breaks = breaks + paste("2018-", c(1:6), sep ="")
breaks = append(paste("2017-", c(11, 12), sep =""), paste("2018-", c(1:6), sep =""))
group_by(mostViews, category, time) %>% summarise(n = n()) %>% ggplot(aes(x = time, y = n, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
breaks = append(paste("2017-", c(11, 12), sep =""), paste("2018-0", c(1:6), sep =""))
group_by(mostViews, category, time) %>% summarise(n = n()) %>% ggplot(aes(x = time, y = n, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time)
group_by(mostViews, category, time) %>% summarise(total_views = sum(views))
group_by(mostViews, category, time) %>% summarise(total_views = sum(views)) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, color = category)) + geom_line() + facet_wrap()
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, color = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views)))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ungroup() %>% group_by(category) %>% ggplot(aes(x = time, y = total_views)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ungroup() %>% group_by(category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ungroup() %>% ggplot(aes(x = time, y = total_views)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ungroup() %>% ggplot(aes(x = time, y = total_views)) + geom_line() + facet_wrap(.~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ungroup() %>% ggplot(aes(x = time, y = total_views)) + geom_line() + facet_wrap(~ factor(category))
group_by(mostViews, category, time) %>% summarise(total_views = sum(views)) %>% ungroup() %>% ggplot(aes(x = time, y = total_views)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = sum(views)) %>% ggplot(aes(x = time, y = total_views)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = sum(views))
group_by(mostViews, category, time) %>% summarise(total_views = sum(views)) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = sum(views)) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views)) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views)) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
mostViews = mutate(mostViews, time = format(publish_time, "%Y-%m"))
breaks = append(paste("2017-", c(11, 12), sep =""), paste("2018-0", c(1:6), sep =""))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
# videos published heat map : 每周二到四下午四點左右為影片發布熱點, Sunday is 0.
table(format(youtube$publish_time,"%H"), format(youtube$publish_time,"%w")) %>% as.data.frame.matrix %>% d3heatmap(F, F, col = colorRamp(c("seagreen", "lightyellow", "red")))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
# video publish time : 下午 4 點左右為影片發布熱點
mutate(mostViews, hour = hour(publish_time)) %>% group_by(hour) %>% summarise(n = n()) %>% ggplot(aes(x = hour, y = n)) + geom_line() + scale_x_continuous(breaks=c(0:23)) + labs(x = "hour", y = "number of videos") + geom_vline(xintercept = 16 , color = "#ff2244", size = 1)
# Number of videos by weekdays : 週五、週四影片發布量最多
mutate(mostViews, weekday = weekdays(publish_time)) %>% group_by(weekday) %>% summarise(n = n()) %>% ggplot(aes(x = reorder(weekday, n), y = n, fill = weekday)) + geom_bar(stat = "identity") + labs(y = "number of videos")
# Number of videos by weekdays : 週三、週二影片發布量最多
mutate(mostViews, weekday = weekdays(publish_time)) %>% group_by(weekday) %>% summarise(n = n()) %>% ggplot(aes(x = reorder(weekday, n), y = n, fill = weekday)) + geom_bar(stat = "identity") + labs(y = "number of videos")
# videos published heat map : 每周二到四下午四點左右為影片發布熱點, Sunday is 0.
table(format(youtube$publish_time,"%H"), format(youtube$publish_time,"%w")) %>% as.data.frame.matrix %>% d3heatmap(F, F, col = colorRamp(c("seagreen", "lightyellow", "red")))
# videos published heat map : 每周二到四下午四點左右為影片發布熱點, Sunday is 0.
table(format(mostViews$publish_time,"%H"), format(mostViews$publish_time,"%w")) %>% as.data.frame.matrix %>% d3heatmap(F, F, col = colorRamp(c("seagreen", "lightyellow", "red")))
# most views video
arrange(mostViews, desc(views))
# most views video
arrange(mostViews, desc(views)) %>% head(10)
# most views video
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title)
# most views video
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title)
# most views video
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, video_title)
# most views video
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, title, views)
# most views video
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, title, views, category)
min(youtube$trending_date)
# add average profit : views / 1000
youtube$avg_profit = youtube$views / 1000
View(youtube)
# add average profit : views / 1000 * 5
youtube$avg_profit = youtube$views / 1000 * 5
# most views of each video，將每部影片最終的資料獨立出來，避免重複統計。
mostViews = group_by(youtube, video_id) %>% filter(views == max(views))
# setwd("~/GitHub/bigdata_team_project/巨量期中")
rm(list=ls()) # clean env
pacman::p_load("data.table", "tidyverse", "sqldf", "jsonlite", "corrplot", "d3heatmap") # load packages
load("./pre_process.rdata") # load pre process data : youtube and mostViews
# channel of most frequently appearing in trending videos : 前 10 最常上熱門的頻道
group_by(youtube, channel_title) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(10) %>% ggplot(aes(x = reorder(channel_title, n), y = n, fill = channel_title)) + geom_bar(stat = "identity") + coord_flip()
# 觀看數前 10 名影片, 音樂 8 : 2 娛樂
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, title, views, category)
# video publish time : 下午 4 點左右為影片發布熱點
mutate(mostViews, hour = hour(publish_time)) %>% group_by(hour) %>% summarise(n = n()) %>% ggplot(aes(x = hour, y = n)) + geom_line() + scale_x_continuous(breaks=c(0:23)) + labs(x = "hour", y = "number of videos") + geom_vline(xintercept = 16 , color = "#ff2244", size = 1)
# Number of videos by weekdays : 週三、週二影片發布量最多
mutate(mostViews, weekday = weekdays(publish_time)) %>% group_by(weekday) %>% summarise(n = n()) %>% ggplot(aes(x = reorder(weekday, n), y = n, fill = weekday)) + geom_bar(stat = "identity") + labs(y = "number of videos")
# videos published heat map : 每周二到四下午四點左右為影片發布熱點, Sunday is 0.
table(format(mostViews$publish_time,"%H"), format(mostViews$publish_time,"%w")) %>% as.data.frame.matrix %>% d3heatmap(F, F, col = colorRamp(c("seagreen", "lightyellow", "red")))
# 哥要的圖
mostViews = mutate(mostViews, time = format(publish_time, "%Y-%m"))
breaks = append(paste("2017-", c(11, 12), sep =""), paste("2018-0", c(1:6), sep =""))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category)) + geom_line() + facet_wrap(~ category)
group_by(mostViews, category, time) %>% summarise(total_views = log10(sum(views))) %>% ggplot(aes(x = time, y = total_views, group = category, color = category)) + geom_line() + xlim(breaks) + theme(axis.text.x = element_text(angle = 90))
View(mostViews)
save(youtube, mostViews, file = "./pre_process.rdata")
# 觀看數前 10 名影片, 音樂 8 : 2 娛樂
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, title, views, category) %>% group_by(category) %>% summarise(n = n()) %>% ggplot(aes(x = category, y = n)) + geom_bar()
# 觀看數前 10 名影片, 音樂 8 : 2 娛樂
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, title, views, category) %>% group_by(category) %>% summarise(n = n()) %>% ggplot(aes(x = category, y = n)) + geom_bar(stat = "identity")
# 觀看數前 10 名影片, 音樂 8 : 2 娛樂
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, title, views, category) %>% group_by(category) %>% summarise(n = n()) %>% ggplot(aes(x = category, y = n, color = category)) + geom_bar(stat = "identity")
# 觀看數前 10 名影片, 音樂 8 : 2 娛樂
arrange(mostViews, desc(views)) %>% head(10) %>% select(channel_title, title, views, category) %>% group_by(category) %>% summarise(n = n()) %>% ggplot(aes(x = category, y = n, fill = category)) + geom_bar(stat = "identity")
# bubble plot
# 可以發現影片倒讚數多，即使喜歡數多，觀看數卻不會提升
ggplot(C, aes(x = likes, y = views, size = dislikes, color = category)) + geom_point(alpha = 0.7) + scale_size(range = c(.1, 24), name="dislikes")
load("./pre_process.rdata") # load pre process data : youtube and mostViews
# category dataframe，新增類別資料框，針對類別作分析
C = group_by(mostViews, category) %>% summarise(likes = mean(likes), dislikes = mean(dislikes), comment_count = mean(comment_count), views = mean(views), trending_days = mean(trending_days))
### 單變數分析
# 什麼類別的影片上熱門的次數最多 : Entertainment、Music、Howto & Style、Comedy、People & Blogs
# Entertainment 上發燒影片最多次，且差距很大，娛樂是觀眾接受度最高且熱度最高的類別。
group_by(youtube, category) %>% summarise(n = n()) %>% arrange(desc(n)) %>% ggplot(aes(x = reorder(category, n), y = n, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類別的影片總觀看數最多 : Music、Entertainment、Film & Animation、Comedy、People & Blogs
group_by(mostViews, category) %>% summarise(total_views = sum(views)) %>% ggplot(aes(x = reorder(category, total_views), y = total_views, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類型的影片觀眾參與度最高(喜歡數 + 觀看數 + 評論數) : Music、Entertainment、Film & Animation、Comedy、People & Blogs
group_by(mostViews, category) %>% summarise(engagement = sum(likes + views + comment_count)) %>% arrange(desc(engagement)) %>% ggplot(aes(x = reorder(category, engagement), y = engagement, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類別的影片平均上熱門時間最久 : Shows、Gaming、Music、Film & Animation、Howto & Style
group_by(youtube, category) %>% summarise(days = mean(trending_days)) %>% ggplot(aes(x = reorder(category, days), y = days, fill = category)) + geom_bar(stat = "identity") + coord_flip()
### 雙變數分析
ggplot(C, aes(x = likes, y = dislikes)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = comment_count)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = views)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = trending_days)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = comment_count)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = views)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = trending_days)) + geom_point() + geom_smooth(method = "lm", se = F)
# 相關係數 > 0.8 高度正相關 0.5 ~ 0.8 顯著正相關 0.3 ~ 0.5 低度正相關
# likes 與 views、comment_count 有顯著正相關，對於喜歡影片的人來說是蠻正常的
# 但可以發現 dislikes 與 comment_count 有最高的正相關，似乎討人厭的影片評論區能夠引發觀眾論戰。
category_cor = cor(C[, -1])
corrplot(category_cor, method="number", type="upper")
# heatmap
top10 = names(head(sort(table(mostViews$category),decreasing = T), 10))
table(format(mostViews[mostViews$category %in% top10, ]$publish_time,"%H"), mostViews[mostViews$category %in% top10, ]$category) %>% as.data.frame.matrix %>% d3heatmap(F, F, col = colorRamp(c("seagreen", "lightyellow", "red")))
### 多變數分析
# 各類別喜歡數、不喜歡數、評論數走勢
dfplot = C[, c(1:4)] %>% gather(key, value, -category)
ggplot(dfplot, aes(x = category, y = value, group = key, color = key)) + geom_line() + theme(axis.text.x = element_text(angle = 90))
# bubble plot
# 可以發現影片倒讚數多，即使喜歡數多，觀看數卻不會提升
ggplot(C, aes(x = likes, y = views, size = dislikes, color = category)) + geom_point(alpha = 0.7) + scale_size(range = c(.1, 24), name="dislikes")
youtube$video_error_or_removed
table(youtube$video_error_or_removed)
youtube[youtube$video_error_or_removed == T, ]
youtube[youtube$video_error_or_removed == T, ]$title
youtube[youtube$video_error_or_removed == T, ]$views
head(sort(youtube$views))
sort(youtube$views)
head(sort(youtube$views))
youtube$views %in% head(sort(youtube$views))
youtube[youtube$views %in% head(sort(youtube$views)), ]
youtube[youtube$views %in% head(sort(youtube$views)), ]$title
nrow(youtube[youtube$trending_date == "2017-11-14"])
nrow(youtube[format(youtube$trending_date) == "2017-11-14"])
format(youtube$trending_date)
nrow(youtube[format(youtube$trending_date) == "2017-11-14", ])
nrow(youtube[format(youtube$trending_date) == "2017-11-15", ])
#
nrow(youtube[format(youtube$trending_date) == "2017-11-14", ])
# 一天最多 200 支影片上熱門
nrow(youtube[format(youtube$trending_date) == "2017-11-14", ])
#
group_by(mostViews, trending_days)
#
group_by(mostViews, trending_days) %>% summarise(n = n())
#
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = trending_days, y = n)) + geom_bar(stat = "identity")
#
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = reorder(trending_days, n), y = n, fill = trending_days)) + geom_bar(stat = "identity")
#
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = trending_days, y = n, fill = trending_days)) + geom_bar(stat = "identity")
#
breaks = c(1:30)
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = trending_days, y = n, fill = trending_days)) + geom_bar(stat = "identity") + xlim(breaks)
#
breaks = c(0:30)
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = trending_days, y = n, fill = trending_days)) + geom_bar(stat = "identity") + xlim(breaks)
#
breaks = as.character(c(0:30))
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = trending_days, y = n, fill = trending_days)) + geom_bar(stat = "identity") + xlim(breaks)
mean(mostViews$trending_days)
# 影片上熱門天數集中在 0 ~ 6 天
breaks = as.character(c(0:30))
mean(mostViews$trending_days) # 平均上熱門 6.44 天
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = trending_days, y = n, fill = trending_days)) + geom_bar(stat = "identity") + xlim(breaks)
# 一天最多 200 支影片上熱門
nrow(youtube[format(youtube$trending_date) == "2017-11-14", ])
# 影片上熱門天數集中在 0 ~ 6 天
breaks = as.character(c(0:30))
mean(mostViews$trending_days) # 平均上熱門 6.44 天
group_by(mostViews, trending_days) %>% summarise(n = n()) %>% ggplot(aes(x = trending_days, y = n, fill = trending_days)) + geom_bar(stat = "identity") + xlim(breaks)
View(C)
# 每個類別平均上熱門的天數
ggplot(C, aes(x = category, y = trending_days)) + geom_bar()
# 每個類別平均上熱門的天數
ggplot(C, aes(x = category, y = trending_days)) + geom_bar(stat = "identity")
# 每個類別平均上熱門的天數
ggplot(C, aes(x = category, y = trending_days)) + geom_bar(stat = "identity") + theme(asis.x.text = element_text(angle = 90))
# 每個類別平均上熱門的天數
ggplot(C, aes(x = category, y = trending_days)) + geom_bar(stat = "identity") + theme(axis.x.text = element_text(angle = 90))
# 每個類別平均上熱門的天數
ggplot(C, aes(x = category, y = trending_days)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90))
# 每個類別平均上熱門的天數
ggplot(C, aes(x = reorder(category, trending_days), y = trending_days, fill = category)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90))
ggplot(mostViews, aes(x = trending_days)) + geom_boxplot()
# 每個類別平均上熱門的天數 : shows 平均上熱門天數最多
ggplot(C, aes(x = reorder(category, trending_days), y = trending_days, fill = category)) + geom_bar(stat = "identity") + theme(axis.text.x = element_text(angle = 90))
