<<<<<<< HEAD
View(X0)
TR = subset(A, spl)
pacman::p_load(dplyr,ggplot2,caTools)
rm(list=ls(all=TRUE))
load("data/tf3.rdata")
TR = subset(A, spl)
TS = subset(A, !spl)
View(TR)
cls
clm
install.packages(c("epiDisplay", "expm", "ggplot2movies", "RMySQL"))
print("Hello R!")
num <- c(1,2,3,4,5) #use c() to create/combine vectors
####################
#### Unit 2 R codes
####################
rm(list = ls())
print("Hello R!")
v = 1:3
print("Hello R!")
num <- c(1,2,3,4,5) #use c() to create/combine vectors
i = 1
is.vector(num)
is.vector(i)
num + 1
sum(num)
pord(num)
prod(num)
sq = function(x) x^2
sq(2)
cube = function(x) x^3
cube(2)
func = function(f) f(2)
func(sq)
func(cube)
# R 語言任何一個操作都是 function call
1 + 2
"+"(1, 2)
1 * 3
"*"(1, 3)
## Operators
# From:To
v = 1:5
# Load all datasets and functions on the RStudio server
library(bigDataR)
v = 6:10
# Matrix Multiplication, dot and outer product
m1 = matrix(1:4, ncol = 2, byrow = T);m1
m1 * m1
m1 %*% m1
v = 1:3
v * v # scalar/cell product
v %*% v # dot product
v %o% v # outer product
outer(v, v, "*")
outer(v, v, FUN = "+")
outer(v, v, FUN = function(v1, v2) paste(v1, v2, sep ="---") )
m1 %*% m1
m1 %*% m1 %*% m1
library(expm)
m1 %^%  3
# Vector/Scalar AND and OR
T | F
c(F, T, T) | c(T, F, T)
c(F, T, T) || c(T, F, T)
# Short-circuit
x = 0
(x == 0) & (x <- x + 1)
(x == 0) & (x <- x + 1)
(x == 0) & (x <- x + 1)
(x == 0) && (x <- x + 1)
(x == 0) && (x <- x + 1)
(x == 0) || (x <- x + 1)
(x == 4) || (x <- x + 1)
(x == 4) || (x <- x + 1)
rm(ls())
rm(list = ls())
# %in%
'a' %in% letters
letters
# %in%
'a' %in% letters
c('a', 'b', '1') %in% letters
# Package::function() or Package::object
a = 1:5
mean = function(x) print("a function called \"mean\" ")
mean(a)
base::mean(a)
x = 3
is.vector(x)
is.numeric(x)
is.integer(x)
####################
#### Unit 2 R codes
####################
rm(list = ls())
x = 3
is.vector(3)
x = 3
is.vector(3) # R 最小單位 : vector
typeof(x)
mean(x = 1:10) # "=" is used as a function argument binding
mean(x <- 1:10) # "<-" is used as a variable assignment
mean(x = 1:10) # "=" is used as a function argument binding ( mean 的參數 x 為 1 : 10)
mean(x <- 1:10) # "<-" is used as a variable assignment (將 1 : 10 存入變數 x，並傳給 mean 的參數 x)
mean(x = x <- 1:10)
mean(x = x = 1:10) # "=" is used as a function argument binding ( mean 的參數 x 為 1 : 10)
mean(x = x <- 1:10)
v3 = vector(mode="character", length= 3)
v4 = vector(mode="logical", length= 2)
a = array(c(1,2,3,4,5,6), dim=c(1,2,3)) # 1 by 2 by 3
a
a = array(c(1,2,3,4,5,6), dim=c(1,2,3)) # 1 by 2 by 3
a
dim(a) # get the dimension of the array
dim(a) # get the dimension of the array
dim(a) # get the dimension of the array
v1 = c(9,8,7)
v2 = c("a","b","c")
#combine 2 vectors
d = data.frame(x1 = v1, x2 = v2, stringsAsFactors = F)
View(d)
str(d) # show the structure of the data frame “d”
# Using package "data.table"
library(data.table)
d_dt = data.table(d)
str(d_dt) # "data.table" is also a kind of data frame
# key-value pairs of data
L = list(k1 = c(9, 8, 7), k2 = c("a","b","c"), k3 = c(1))
L[1:2]
L
data.frame(L)
L$k1  # get the data in the list L with the key “k1”
L$k3
# 常用來表示 ordinal、nominal 變數
group = c("control", "treatment", "treatment", "control")
group
group_f = factor(group, levels=c("treatment", "control"))
group_f  # check the actual data type of “group_f”
typeof(group_f)
unclass(group_f) # remove class attributes to get real data values
unclass(group_f) # remove class attributes to get real data values
smoker = as.data.frame(smoker)
library('bigDataR')
library('bigDataR')
####################
#### Unit 2 R codes
####################
rm(list = ls())
library('bigDataR')
install.packages('bigDataR')
library('bigDataR')
library('bigDataR')
library('bigDataR')
a = c(1,2,3,4)
a
is.vector(a)
is.matrix(a)
m = as.matrix(a)
m
is.matrix(m)
t(m) # transpose the matrix
a
is.matrix(a)
m = as.matrix(a, byrow = T)
m
m = as.matrix(a, nrow = 1)
m
m = as.matrix(a, ncol = 4)
m
a = c(1,2,3,4)
m = as.matrix(a, ncol = 4)
m
a = c(1,2,3,4)
a
is.vector(a)
is.matrix(a)
m = as.matrix(a, ncol = 4)
m
is.matrix(m)
t(m) # transpose the matrix
m = as.matrix(a, ncol = 4, nrow = 1)
m
m = as.matrix(a, ncol = 2, nrow = 2)
m
a = c(1,2,3,4)
a
is.vector(a)
is.matrix(a)
m = as.matrix(a, ncol = 2, nrow = 2)
m
is.matrix(m)
t(m) # transpose the matrix
m = as.matrix(1:4, ncol = 2, nrow = 2)
m
m = as.matrix(1:4, ncol = 2, nrow = 2,byrow = T)
m
m = matrix(1:4, ncol = 2, nrow = 2,byrow = T)
m
m = matrix(a, nrow = 1,byrow = T)
m
m = as.matrix(a)
m
is.matrix(m)
t(m) # transpose the matrix
a = NA ; typeof(a)
a = NA ; typeof(a)
# NA : 存在但遺失，佔記憶體空間
a = NA ; typeof(a)
object.size(a) # get the object size (bytes) in memory
# NULL : 不存在，不佔記憶體空間
b = NULL; typeof(b)
object.size(b)
square = function(x = NULL){
return(ifelse(is.null(x), "NULL", x^2 ) );
}
# if x is not NULL, then output x squared.
square()
square(3)
x = 'global'
printXY = function(){
y = 'local';
print(x);
print(y);
}
printXY()
x
y
# assign a new string to x then print
x = 'global_x'
printX = function(x){
print(x); x = 'local_x'; print(x);
}
printX(x)
# Set operations, an R ellipsis example
setOper = function(f, ...){
el = list(...)
return(Reduce(f, el))
}
setOper(intersect, 1:5, 2:6, 3:5)
setOper(union, 1:5, 2:6, 3:5)
setOper(intersect, 1:5, 2:6, 3:5)
# Set operations, an R ellipsis example
setOper = function(f, ...){
print(..3)
el = list(...)
return(Reduce(f, el))
}
setOper(intersect, 1:5, 2:6, 3:5)
# A example of function factory
powFunc = function(n){
return(function(k) k^n)
}
square = powFunc(2)
square(3)
cube = powFunc(3)
cube(2)
powFunc(5)(2)
f = function(x){
if(x > 10){
print("x is great than 10");
} else if( x >=0 & x <=10) {
print("x is between 0 and 10");
} else {
print("x is less than 0");
}
}
f(-1)
f(5)
f(11)
library(ggplot2movies)
movies = as.data.frame(movies); movies$longshort = ""
View(movies)
movies$length > 120
# Very bad practice with for loop. Don't do this!
system.time({
for(i in 1:nrow(movies)){
if(movies[i, "length"] > 120) movies[i, "longshort"] = "long"
else movies[i, "longshort"] = "short" }
})
# Use ifelse() instead
system.time(
movies$longshort <- ifelse(movies$length > 120, "long", "short"))
# Or simply vectorized it!
system.time({
movies[movies$length > 120, "longshort"] = "long"
movies[movies$length <= 120, "longshort"] = "short"
})
for(i in c('a','b')) print(i)
for(k in 1:3) {
if(k == 3) break; print(k);
}
x = 3;
while(x > 0){
print(x);
x = x - 1;
}
switch(3, 'a' = {x = x + 5;},
'b' = {x = 999},'c' = {x = 'ABC'}
)
x # 2nd statement after expr
bmi_num = c(19,39,20,22,34,24);
bmi_cat = cut(x=bmi_num,breaks=c(0,18.5,24.9, 29.9, Inf),
labels=c('Underweight','Normal weight','Overweight','Obesity'));
bmi_cut_str = "lo:18.5 = 'Underweight';
18.5:24.9 = 'Normal weight';
24.9:29.9 = 'Overweight';
29.9:hi = 'Obesity'"
bmi_cat = car::recode(bmi_num, bmi_cut_str, as.factor = T,
levels = c('Underweight','Normal weight','Overweight','Obesity'))
table(bmi_cat)
xtabs(~ bmi_cat,  bmi_cat)
xtabs(~ bmi_cat)
xtabs(~ bmi_cat)
table(bmi_cat)
write.csv(as.data.frame(matrix(runif(10 ^ 6 ,0,1),  nrow=1000)), file='rnum.csv');
write.csv(as.data.frame(matrix(runif(10 ^ 6 ,0,1),  nrow=1000)), file='rnum.csv');
# An ~18 MB CSV file.
file.info("rnum.csv")$size; # get file size
system.time({rnum = read.csv(file= "rnum.csv", header=T)});
rm(rnum); library("data.table"); #load package data.table
system.time({ rnum = fread(input="rnum.csv")});
rm(rnum); library("sqldf"); # load package sqldf
system.time({ rnum = read.csv2.sql(file="rnum.csv", header=T,sep = ",");})
rm(rnum); library("sqldf"); # load package sqldf
system.time({ rnum = read.csv2.sql(file="rnum.csv", header=T,sep = ",");})
rm(rnum); library("data.table"); #load package data.table
system.time({ rnum = fread(input="rnum.csv")});
rm(rnum); library("data.table"); #load package data.table
system.time({ rnum = fread(input="rnum.csv")});
rm(rnum); library("sqldf"); # load package sqldf
system.time({ rnum = read.csv2.sql(file="rnum.csv", header=T,sep = ",");})
# rank by "mpg“ & create a new dataset
data.frame("car_name" = rownames(mtcars),
"mpg" = mtcars$mpg,
"rank" = rank(mtcars$mpg, ties.method = "first"))
rownames(mtcars)
mtcars
# rank by "mpg“ & create a new dataset
data.frame("car_name" = rownames(mtcars),
"mpg" = mtcars$mpg,
"rank" = rank(mtcars$mpg, ties.method = "first"))
#############################################################################
## 資料集說明 :
# - 來源 : [kaggle](https://www.kaggle.com/datasnaek/youtube-new)
# - 資料集 : youtube 發燒影片列表資料，有 US、CA、DE、FR、GB、IN、JP、KR、MX、RU，共 10 個國家的統計資料。
# - 資料集大小 : 40949 筆資料、16個欄位
# - 時間 : 2017-12-01 ~ 2018-05-31
## 欄位說明 :
# - video_id : 影片 ID
# - trending_date : 發燒日期
# - title : 影片標題
# - channel_title : 頻道標題
# - category_id : 類別 ID
# - publish_time : 影片發布時間
# - tags : 標籤
# - views : 觀看數
# - likes : 喜歡數
# - dislikes : 倒讚數
# - comment_count : 評論數
# - thumbnail_link : 影片縮圖連結
# - comments_disabled : 是否允許評論
# - ratings_disabled : 是否允許評分
# - video_error_or_removed : 影片錯誤或移除
# - description : 影片描述
## 關鍵指標
# 1. YouTube 參與度指標 (觀看次數、喜歡人數、不喜歡人數、訂閱數) 代表觀眾與影片或頻道互動的次數。這些指標可以視為衡量影片或頻道整體熱門程度的重要指標。([Youtube](https://support.google.com/youtube/answer/2991785?hl=zh-Hant)) <br><br>
# 2. 發燒影片會將許多指標納入參考，以下為其中幾項： ([Youtube](https://support.google.com/youtube/answer/7239739?hl=zh-Hant))
# - 觀看次數
# - 影片產生觀看次數的速度 (即「熱度」)
# - 觀看次數的來源 (包括 YouTube 以外的來源)
# - 影片已發布多久
# - 與同頻道最近上傳的其他影片相比，影片的表現如何
############################################################################
=======
data.table::fread("./tea/profiles.csv")
(profiles = read.csv("./2020BAR/tea/profiles.csv") )
(profiles = read.csv("./ConjointApp/2020BAR/tea/profiles.csv") )
(profiles = read.csv("../tea/profiles.csv") )
(profiles = read.csv("//tea/profiles.csv") )
Sys.getlocale()
(profiles = read.csv("./tea/profiles.csv") )
data("mtcars")
View(X0)
View(Z)
View(Z0)
data("mtcars")
force(mtcars)
?mean
?lm
nrow(A)
top100 = data.table::fread("Top100.csv")
library(tidyverse)
airbnb = data.table::fread("AB_NYC_2019.csv")
vgsales = data.table::fread("my_vgsales.csv")
top100 = data.table::fread("Top100.csv")
sapply(airbnb, function(x) sum(is.na(x)))
na.omit(airbnb)
is.na(airbnb)
count(is.na(airbnb))
sum(is.na(airbnb))
sapply(airbnb, function(x) sum(is.na(x)))
na.omit(airbnb)
drop_na(airbnb)
library(tidyverse)
sapply(airbnb, function(x) sum(is.na(x)))
drop_na(airbnb)
na.omit(airbnb)
sum(is.na(airbnb))
a = na.omit(airbnb)
sum(is.na(a))
View(airbnb)
table(airbnb$neighbourhood_group, airbnb$room_type)
cor(airbnb$neighbourhood_group, airbnb$room_type)
cor(b)
b = table(airbnb$neighbourhood_group, airbnb$room_type)
cor(b)
table(airbnb$neighbourhood_group, airbnb$room_type)
cor(airbnb$neighbourhood_group, airbnb$room_type)
sapply(airbnb, function(x) sum(is.na(x)))
airbnb = na.omit(airbnb)
sum(is.na(a))
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10)
library(tidyverse)
install.packages("tidyverse")
library(tidyverse)
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10)
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10, sort = T)
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10)
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10) %>% arrange(total_price)
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10) %>% arrange(desc(total_price))
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10, total_price) %>% arrange(desc(total_price))
table(airbnb$neighbourhood_group, airbnb$room_type)
airbnb$room_type
table(airbnb$neighbourhood_group, airbnb$room_type)
table(airbnb$neighbourhood_group, airbnb$room_type)
my_vgsales = data.table::fread("my_vgsales.csv")
complete.cases(my_vgsales)
my_vgsales <- my_vgsales[complete.cases(my_vgsales), ]
my_vgsales %>%  group_by(Genre) %>% arrange(desc(global_sales))
my_vgsales = my_vgsales %>% mutate(global_sales=my_vgsales$NA_Sales+my_vgsales$JP_Sales+my_vgsales$EU_Sales+my_vgsales$Other_Sales)
my_vgsales %>%  group_by(Genre) %>% arrange(desc(global_sales))
table(my_vgsales$genre, my_vgsales$global_sales)
my_vgsales %>%  group_by(Genre) %>% arrange(desc(global_sales))
View(my_vgsales)
# 2.4
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = global_sales)
# 2.4
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales))
# 2.4
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales)) %>% top_n(5, Total_Sales)
# 2.4
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales)) %>% top_n(5, Total_Sales) %>% arrange(desc(Total_Sales))
library(sqldf)
sqldf(
select *
from my_vgsales
)
sqldf(
"select *
from my_vgsales"
)
# 2.4
my_vgsales_top5 = my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales)) %>% top_n(5, Total_Sales) %>% arrange(desc(Total_Sales))
View(my_vgsales_top5)
sqldf(
"select *
from my_vgsales"
)
sqldf(
"select *
from my_vgsales_top5"
)
sqldf(
"select Name, SUM(global_sales)
from my_vgsales
Group by Name"
)
sqldf(
"select Name, SUM(Total_Sales = global_sales)
from my_vgsales
group by Name
order by "
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by "
)
sqldf(
"select Name, SUM(global_sales)
from my_vgsales"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group_by Name"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales"
)
sqldf(
"select Top 5 Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
Fetch First 10 Row Only"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
fetch first 10 row only"
)
sqldf(
"select top 5 Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
fetch first 10 row only"
)
sqldf(
"select top 5 (Name, SUM(global_sales) as Total_Sales)
from my_vgsales
group by Name
order by Total_Sales
fetch first 10 row only"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
fetch first 10 row only"
)
sqldf(
"select top 5 (Name, SUM(global_sales) as Total_Sales)
from my_vgsales
group by Name
order by Total_Sales"
)
sqldf(
"select top 5 Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by SUM(global_sales)"
)
sqldf(
"select top 5 *
from (select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales)"
)
sqldf(
"select top 5 *
from sqldf(select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales)"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
where rownum <= 5"
)
sqldf(
"
select *
from sqldf(select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales)
where rownum <= 5"
)
sqldf(
"select *
from sqldf(select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales)
where rownum <= 5"
)
sqldf(
"select *
from (select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales)
where rownum <= 5"
)
sqldf(
"select *
from (select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales)
where ROWNUM <= 5"
)
sqldf(
"from sqldf(select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales)
desc limit 5"
)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
desc limit 5"
)
# 2.4
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales)) %>% top_n(5, Total_Sales) %>% arrange(desc(Total_Sales))
install.packages("tidyverse")
library(tidyverse)
library(tidyverse)
airbnb = data.table::fread("AB_NYC_2019.csv")
my_vgsales = data.table::fread("my_vgsales.csv")
top100 = data.table::fread("Top100.csv")
sapply(airbnb, function(x) sum(is.na(x)))
airbnb = na.omit(airbnb)
sum(is.na(a))
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10, total_price) %>% arrange(desc(total_price))
table(airbnb$neighbourhood_group, airbnb$room_type)
complete.cases(my_vgsales)
my_vgsales <- my_vgsales[complete.cases(my_vgsales), ]
my_vgsales = my_vgsales %>% mutate(global_sales=my_vgsales$NA_Sales+my_vgsales$JP_Sales+my_vgsales$EU_Sales+my_vgsales$Other_Sales)
my_vgsales %>%  group_by(Genre) %>% arrange(desc(global_sales))
# 2.4
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales)) %>% top_n(5, Total_Sales) %>% arrange(desc(Total_Sales))
library(sqldf)
sqldf(
"select Name, SUM(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
desc limit 5"
)
head(answer)
answer = my_vgsales %>%  group_by(Genre) %>% arrange(desc(global_sales))
head(answer)
my_vgsales %>%  group_by(Genre) %>% summarise(n = nrow)
my_vgsales %>%  group_by(Genre) %>% summarise(n = nrow())
my_vgsales %>%  group_by(Genre) %>% summarise(n = n())
my_vgsales %>%  group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n))
complete.cases(my_vgsales)
my_vgsales <- my_vgsales[complete.cases(my_vgsales), ]
my_vgsales = my_vgsales %>% mutate(global_sales=my_vgsales$NA_Sales+my_vgsales$JP_Sales+my_vgsales$EU_Sales+my_vgsales$Other_Sales)
my_vgsales %>%  group_by(Genre) %>% arrange(desc(global_sales))
my_vgsales %>%  group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n))
my_vgsales %>%  group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n))
my_vgsales %>%  group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(5)
my_vgsales %>% filter(Publisher=="Nintendo") %>% group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(5)
my_vgsales %>% filter(Publisher == "Nintendo") %>% group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(5)
n(my_vgsales$Platform)
nrow(my_vgsales$Platform)
n(my_vgsales$Platform)
table(my_vgsales$Platform)
n(my_vgslaes)
#1.
#1.1
library("data.table")
library(dplyr)
airbnb = fread(input="/Users/killercrow/Downloads/AB_NYC_2019.csv")
sapply(airbnb, function(x) sum(is.na(x)))
airbnb = fread(input="/Users/killercrow/Downloads/AB_NYC_2019.csv")
sapply(airbnb, function(x) sum(is.na(x)))
#1.
#1.1
library("data.table")
library(dplyr)
airbnb = fread(input="/Users/killercrow/Downloads/AB_NYC_2019.csv")
sapply(airbnb, function(x) sum(is.na(x)))
airbnb = fread(input="/Users/killercrow/Downloads/AB_NYC_2019.csv")
sapply(airbnb, function(x) sum(is.na(x)))
#1.
#1.1
library("data.table")
library(dplyr)
airbnb = fread(input="AB_NYC_2019.csv")
sapply(airbnb, function(x) sum(is.na(x)))
#last_review = 9936
#reviews_per_month = 9936
airbnb = na.omit(airbnb)
#1.2
airbnb %>%
group_by(host_id) %>%
summarise(total_price = sum(price)) %>%
top_n(10, total_price) %>%
arrange(desc(total_price))
#1.3
table(airbnb$neighbourhood_group, airbnb$room_type)
chisq.test(table(airbnb$neighbourhood_group, airbnb$room_type))
#2
my_vgsales = fread(input="my_vgsales.csv")
library(sqldf)
#2.1
complete.cases(my_vgsales)
my_vgsales <- my_vgsales[complete.cases(my_vgsales), ]
#2.2
my_vgsales = my_vgsales %>% mutate(global_sales=my_vgsales$NA_Sales+my_vgsales$JP_Sales+my_vgsales$EU_Sales+my_vgsales$Other_Sales)
#2.3
my_vgsales %>% filter(Publisher == "Nintendo") %>% group_by(Genre)
#2.4.1
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales)) %>% top_n(5, Total_Sales) %>% arrange(desc(Total_Sales))
#2.4.2
data1 = sqldf('select Name, sum(global_sales) as Total_Sales from my_vgsales GROUP BY Name Order BY Total_Sales DESC Limit 5', row.names=T)
data1
#2.5.1
#蝜芸??之??????耦
ggplot(my_vgsales, aes(x = my_vgsales$NA_Sales)) + geom_density(alpha = 0.3) +xlim(-1,1)
ggplot(my_vgsales, aes(x = my_vgsales$EU_Sales)) + geom_density(alpha = 0.3) +xlim(-1,1)
#2.3
my_vgsales %>% filter(Publisher == "Nintendo") %>% group_by(Genre)
#1.3
table(airbnb$neighbourhood_group, airbnb$room_type)
chisq.test(table(airbnb$neighbourhood_group, airbnb$room_type))
#2.5.1
#蝜芸??之??????耦
ggplot(my_vgsales, aes(x = my_vgsales$NA_Sales)) + geom_density(alpha = 0.3) +xlim(-1,1)
ggplot(my_vgsales, aes(x = my_vgsales$EU_Sales)) + geom_density(alpha = 0.3) +xlim(-1,1)
ad.test(my_vgsales$NA_Sales)
ad.test(my_vgsales$EU_Sales)
##??絲靘??虜???
#?瑼Ｗ??撘摰?
library(nortest)
ad.test(my_vgsales$NA_Sales)
ad.test(my_vgsales$EU_Sales)
lillie.test(my_vgsales$NA_Sales)
lillie.test(my_vgsales$EU_Sales)
#2.5.2
#????頧??actor
op100$Area = factor(Top100$Area)
#2.5.2
#????頧??actor
Top100$Area = factor(Top100$Area)
Top100$Genre = factor(Top100$Genre)
#1.
#1.1
library("data.table")
library(dplyr)
airbnb = fread(input="/Users/killercrow/Downloads/AB_NYC_2019.csv")
sapply(AB_NYC_2019, function(x) sum(is.na(x)))
#?????ol,global sales 撠????????um韏瑚??
#2.3
my_vgsales %>% filter(Publisher == "Nintendo") %>% group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(5)
library(tidyverse)
airbnb = data.table::fread("AB_NYC_2019.csv")
my_vgsales = data.table::fread("my_vgsales.csv")
top100 = data.table::fread("Top100.csv")
sapply(airbnb, function(x) sum(is.na(x)))
airbnb = na.omit(airbnb)
sum(is.na(a))
airbnb %>% group_by(host_id) %>% summarise(total_price = sum(price)) %>% top_n(10, total_price) %>% arrange(desc(total_price))
# 1.3
neighbour_type = table(airbnb$neighbourhood_group, airbnb$room_type)
chisq.test(neighbour_type)
# 1.3
neighbour_type = table(airbnb$neighbourhood_group, airbnb$room_type)
neighbour_type
# 1.1
sapply(airbnb, function(x) sum(is.na(x)))
chisq.test(neighbour_type)
# 1.1
sapply(airbnb, ifelse(is.na(), 1, 0))
# 2.1
game_sales = na.omit(my_vgsales)
# team member solution
complete.cases(my_vgsales)
my_vgsales <- my_vgsales[complete.cases(my_vgsales), ]
my_vgsales = my_vgsales %>% mutate(global_sales=my_vgsales$NA_Sales+my_vgsales$JP_Sales+my_vgsales$EU_Sales+my_vgsales$Other_Sales)
my_vgsales %>%  group_by(Genre) %>% arrange(desc(global_sales))
# 2.4
my_vgsales %>% group_by(Name) %>% summarise(Total_Sales = sum(global_sales)) %>% top_n(5, Total_Sales) %>% arrange(desc(Total_Sales))
my_vgsales %>% filter(Publisher == "Nintendo") %>% group_by(Genre) %>% summarise(n = n()) %>% arrange(desc(n)) %>% head(5)
sqldf(
"select Name, sum(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
desc limit 5"
)
sqldf::sqldf(
"select Name, sum(global_sales) as Total_Sales
from my_vgsales
group by Name
order by Total_Sales
desc limit 5"
)
MASS
library("MASS")
MASS::UScrime
UScrime = MASS::UScrime
library("MASS", tidyverse)
UScrime = MASS::UScrime
ggplot(UScrime, aes(x = UScrime$prob, fill = factor(UScrime$So))) + geom_density(alpha = .3)
ggplot(UScrime, aes(x = prob, fill = factor(So))) + geom_density(alpha = .3)
UScrime = MASS::UScrime
UScrime
ggplot(UScrime, aes(x = Prob, fill = factor(So))) + geom_density(alpha = .3)
t.test(formula = Prob - So, data = UScrime)
t.test(formula = Prob - So, data = UScrime)
mltools:::one_hot
install.packages("mltools")
mltools:::one_hot
data <- data.frame(
Outcome = seq(1,100,by=1),
Variable = sample(c("Red","Green","Blue"), 100, replace = TRUE)
)
View(data)
mtools::one_hot(data)
mltools::one_hot(data)
mltools::one_hot(as.data.table(data))
library("data.table")
library(data.table)
mltools::one_hot(as.data.table(data))
mltools:::one_hot
dt = data
cols <- colnames(dt)[which(sapply(dt, function(x) is.factor(x) & !is.ordered(x)))]
cols
colnames(dt)[which(sapply(dt, function(x) is.factor(x) & !is.ordered(x)))]
setwd("C:/Users/user/bigdata_team_project/巨量期中")
# setwd("~/GitHub/bigdata_team_project/巨量期中")
>>>>>>> e50799ed3674f58db3b9bed46343315bd2e70f0d
rm(list=ls()) # clean env
pacman::p_load("data.table", "tidyverse", "sqldf", "jsonlite", "corrplot", "d3heatmap") # load packages
yt = read_csv("./USvideos.csv") # read csv
cat("開始日期:", min(yt$trending_date), "結束日期:", max(yt$trending_date))
<<<<<<< HEAD
sapply(yt, function(x) sum(ifelse(is.na(x), 1, 0))) # check NA，discription 有 NA
yt[is.na(yt)] = "" # fill NA，將 discription NA 填為空字串
# load category JSON file，讀取類別 JSON 檔
cjson = fromJSON("./US_category_id.json"); cid = cjson$items$id; ctable = as.data.frame(cid); ctable$category = cjson$items$snippet$title
# add category name to youtube data frame，新增類別名稱欄位
youtube = merge(yt, ctable, by.x = "category_id", by.y = "cid")
# trending_date to Date type，資料型態轉換
youtube$trending_date = as.Date(youtube$trending_date, format = "%y.%d.%m")
# remove 清理環境
rm(list=c("cjson", "ctable", "yt", "cid"))
# add trending_days column，新增每部影片上幾天熱門的欄位
youtube = group_by(youtube, video_id) %>% mutate(trending_days = n())
# most views of each video，將每部影片最終的資料獨立出來，避免重複統計。
mostViews = group_by(youtube, video_id) %>% filter(views == max(views))
# category dataframe，新增類別資料框，針對類別作分析
C = group_by(mostViews, category) %>% summarise(likes = mean(likes), dislikes = mean(dislikes), comment_count = mean(comment_count), views = mean(views), trending_days = mean(trending_days))
# C = C %>% mutate(likes_rate = likes / sum(likes), dislikes_rate = dislikes / sum(dislikes), comment_rate = comment_count / sum(comment_count))
### 單變數分析
# 什麼類別的影片上熱門的次數最多 : Entertainment、Music、Howto & Style、Comedy、People & Blogs
# Entertainment 上發燒影片最多次，且差距很大，娛樂是觀眾接受度最高且熱度最高的類別。
group_by(youtube, category) %>% summarise(n = n()) %>% arrange(desc(n)) %>% ggplot(aes(x = reorder(category, n), y = n, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類別的影片總觀看數最多 : Music、Entertainment、Film & Animation、Comedy、People & Blogs
group_by(mostViews, category) %>% summarise(total_views = sum(views)) %>% ggplot(aes(x = reorder(category, total_views), y = total_views, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類型的影片觀眾參與度最高(喜歡數 + 倒讚數 + 評論數) : Music、Entertainment、Comedy、People & Blogs、Howto & Style
group_by(mostViews, category) %>% summarise(engagement = sum(likes + dislikes + comment_count)) %>% arrange(desc(engagement)) %>% ggplot(aes(x = reorder(category, engagement), y = engagement, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類別的影片平均上熱門時間最久 : Shows、Gaming、Music、Film & Animation、Howto & Style
group_by(youtube, category) %>% summarise(days = mean(trending_days)) %>% ggplot(aes(x = reorder(category, days), y = days, fill = category)) + geom_bar(stat = "identity") + coord_flip()
### 雙變數分析
ggplot(C, aes(x = likes, y = dislikes)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = comment_count)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = views)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = trending_days)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = comment_count)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = views)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = trending_days)) + geom_point() + geom_smooth(method = "lm", se = F)
# 相關係數 > 0.8 高度正相關 0.5 ~ 0.8 顯著正相關 0.3 ~ 0.5 低度正相關
# likes 與 views、comment_count 有顯著正相關，對於喜歡影片的人來說是蠻正常的
# 但可以發現 dislikes 與 comment_count 有最高的正相關，似乎討人厭的影片評論區能夠引發觀眾論戰。
category_cor = cor(C[, -1])
corrplot(category_cor, method="number", type="upper")
### 多變數分析
# 各類別喜歡數、不喜歡數、評論數走勢
dfplot = C[, c(1:4)] %>% gather(key, value, -category)
ggplot(dfplot, aes(x = category, y = value, group = key, color = key)) + geom_line() + theme(axis.text.x = element_text(angle = 90))
# bubble plot
# 可以發現影片倒讚數多，即使喜歡數多，觀看數卻不會提升
ggplot(C, aes(x = likes, y = views, size = dislikes, color = category)) + geom_point(alpha = 0.7) + scale_size(range = c(.1, 24), name="dislikes")
# 喜歡比(likes / dislikes)與評論比(comment_count / views)
# 可以看出 Pets & Animals 有很高的喜歡比，大部分人都很喜歡動物
# Nonprofits & Activism (非營利組織和行動主義) e.g. "TED x Talks"
# Nonprofits & Activism 喜歡比低且評論比高，此類別影片可能較多爭議，很多觀眾討論
mutate(C, likes_prop = likes / dislikes, comment_prop = 1000 * (comment_count / views)) %>% ggplot(aes(x = category)) + geom_col(aes(y = likes_prop), size = 1, color = "darkblue", fill = "white") + geom_line(aes(y = comment_prop), size = 1.5, color="red", group = 1) + scale_y_continuous(sec.axis = sec_axis(~./100, name = "comment_prop")) + theme(axis.text.x = element_text(angle = 90))
# heatmap
top10 = names(head(sort(table(mostViews$category),decreasing = T), 10))
table(format(mostViews[mostViews$category %in% top10, ]$publish_time,"%H"), mostViews[mostViews$category %in% top10, ]$category) %>% as.data.frame.matrix %>% d3heatmap(F,F,col=colorRamp(c('seagreen','lightyellow','red')))
rm(list=ls()) # clean env
pacman::p_load("data.table", "tidyverse", "sqldf", "jsonlite", "corrplot", "d3heatmap") # load packages
yt = read_csv("./USvideos.csv") # read csv
cat("開始日期:", min(yt$trending_date), "結束日期:", max(yt$trending_date))
setwd("~/GitHub/bigdata_team_project/巨量期中")
setwd("~/GitHub/bigdata_team_project/巨量期中")
rm(list=ls()) # clean env
pacman::p_load("data.table", "tidyverse", "sqldf", "jsonlite", "corrplot", "d3heatmap") # load packages
yt = read_csv("./USvideos.csv") # read csv
cat("開始日期:", min(yt$trending_date), "結束日期:", max(yt$trending_date))
=======
>>>>>>> e50799ed3674f58db3b9bed46343315bd2e70f0d
sapply(yt, function(x) sum(ifelse(is.na(x), 1, 0))) # check NA，discription 有 NA
yt[is.na(yt)] = "" # fill NA，將 discription NA 填為空字串
# load category JSON file，讀取類別 JSON 檔
cjson = fromJSON("./US_category_id.json"); cid = cjson$items$id; ctable = as.data.frame(cid); ctable$category = cjson$items$snippet$title
# add category name to youtube data frame，新增類別名稱欄位
youtube = merge(yt, ctable, by.x = "category_id", by.y = "cid")
# trending_date to Date type，資料型態轉換
youtube$trending_date = as.Date(youtube$trending_date, format = "%y.%d.%m")
# remove 清理環境
rm(list=c("cjson", "ctable", "yt", "cid"))
# add trending_days column，新增每部影片上幾天熱門的欄位
youtube = group_by(youtube, video_id) %>% mutate(trending_days = n())
# most views of each video，將每部影片最終的資料獨立出來，避免重複統計。
mostViews = group_by(youtube, video_id) %>% filter(views == max(views))
# category dataframe，新增類別資料框，針對類別作分析
C = group_by(mostViews, category) %>% summarise(likes = mean(likes), dislikes = mean(dislikes), comment_count = mean(comment_count), views = mean(views), trending_days = mean(trending_days))
### 單變數分析
# 什麼類別的影片上熱門的次數最多 : Entertainment、Music、Howto & Style、Comedy、People & Blogs
# Entertainment 上發燒影片最多次，且差距很大，娛樂是觀眾接受度最高且熱度最高的類別。
group_by(youtube, category) %>% summarise(n = n()) %>% arrange(desc(n)) %>% ggplot(aes(x = reorder(category, n), y = n, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類別的影片總觀看數最多 : Music、Entertainment、Film & Animation、Comedy、People & Blogs
group_by(mostViews, category) %>% summarise(total_views = sum(views)) %>% ggplot(aes(x = reorder(category, total_views), y = total_views, fill = category)) + geom_bar(stat = "identity") + coord_flip()
<<<<<<< HEAD
# 什麼類型的影片觀眾參與度最高(喜歡數 + 倒讚數 + 評論數) : Music、Entertainment、Comedy、People & Blogs、Howto & Style
group_by(mostViews, category) %>% summarise(engagement = sum(likes + dislikes + comment_count)) %>% arrange(desc(engagement)) %>% ggplot(aes(x = reorder(category, engagement), y = engagement, fill = category)) + geom_bar(stat = "identity") + coord_flip()
# 什麼類別的影片平均上熱門時間最久 : Shows、Gaming、Music、Film & Animation、Howto & Style
group_by(youtube, category) %>% summarise(days = mean(trending_days)) %>% ggplot(aes(x = reorder(category, days), y = days, fill = category)) + geom_bar(stat = "identity") + coord_flip()
### 雙變數分析
ggplot(C, aes(x = likes, y = dislikes)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = comment_count)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = views)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = likes, y = trending_days)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = comment_count)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = views)) + geom_point() + geom_smooth(method = "lm", se = F)
ggplot(C, aes(x = dislikes, y = trending_days)) + geom_point() + geom_smooth(method = "lm", se = F)
# 相關係數 > 0.8 高度正相關 0.5 ~ 0.8 顯著正相關 0.3 ~ 0.5 低度正相關
# likes 與 views、comment_count 有顯著正相關，對於喜歡影片的人來說是蠻正常的
# 但可以發現 dislikes 與 comment_count 有最高的正相關，似乎討人厭的影片評論區能夠引發觀眾論戰。
category_cor = cor(C[, -1])
corrplot(category_cor, method="number", type="upper")
### 多變數分析
# 各類別喜歡數、不喜歡數、評論數走勢
dfplot = C[, c(1:4)] %>% gather(key, value, -category)
ggplot(dfplot, aes(x = category, y = value, group = key, color = key)) + geom_line() + theme(axis.text.x = element_text(angle = 90))
# bubble plot
# 可以發現影片倒讚數多，即使喜歡數多，觀看數卻不會提升
ggplot(C, aes(x = likes, y = views, size = dislikes, color = category)) + geom_point(alpha = 0.7) + scale_size(range = c(.1, 24), name="dislikes")
filter(C, category != "Music") %>% ggplot(aes(x = likes, y = views, size = dislikes, color = category)) + geom_point(alpha = 0.7) + scale_size(range = c(.1, 24), name="dislikes")
# bubble plot
# 可以發現影片倒讚數多，即使喜歡數多，觀看數卻不會提升
ggplot(C, aes(x = likes, y = views, size = dislikes, color = category)) + geom_point(alpha = 0.7) + scale_size(range = c(.1, 24), name="dislikes")
# 喜歡比(likes / dislikes)與評論比(comment_count / views)
# 可以看出 Pets & Animals 有很高的喜歡比，大部分人都很喜歡動物
# Nonprofits & Activism (非營利組織和行動主義) e.g. "TED x Talks"
# Nonprofits & Activism 喜歡比低且評論比高，此類別影片可能較多爭議，很多觀眾討論
mutate(C, likes_prop = likes / dislikes, comment_prop = 1000 * (comment_count / views)) %>% ggplot(aes(x = category)) + geom_col(aes(y = likes_prop), size = 1, color = "darkblue", fill = "white") + geom_line(aes(y = comment_prop), size = 1.5, color="red", group = 1) + scale_y_continuous(sec.axis = sec_axis(~./100, name = "comment_prop")) + theme(axis.text.x = element_text(angle = 90))
# heatmap
top10 = names(head(sort(table(mostViews$category),decreasing = T), 10))
table(format(mostViews[mostViews$category %in% top10, ]$publish_time,"%H"), mostViews[mostViews$category %in% top10, ]$category) %>% as.data.frame.matrix %>% d3heatmap(F,F,col=colorRamp(c('seagreen','lightyellow','red')))
# 喜歡比(likes / dislikes)與評論比(comment_count / views)
# 可以看出 Pets & Animals 有很高的喜歡比，大部分人都很喜歡動物
# Nonprofits & Activism (非營利組織和行動主義) e.g. "TED x Talks"
# Nonprofits & Activism 喜歡比低且評論比高，此類別影片可能較多爭議，很多觀眾討論
mutate(C, likes_prop = likes / dislikes, comment_prop = 1000 * (comment_count / views)) %>% ggplot(aes(x = category)) + geom_col(aes(y = likes_prop), size = 1, color = "darkblue", fill = "white") + geom_line(aes(y = comment_prop), size = 1.5, color="red", group = 1) + scale_y_continuous(sec.axis = sec_axis(~./100, name = "comment_prop")) + theme(axis.text.x = element_text(angle = 90))
# heatmap
top10 = names(head(sort(table(mostViews$category),decreasing = T), 10))
table(format(mostViews[mostViews$category %in% top10, ]$publish_time,"%H"), mostViews[mostViews$category %in% top10, ]$category) %>% as.data.frame.matrix %>% d3heatmap(F,F,col=colorRamp(c('seagreen','lightyellow','red')))
table(format(mostViews[mostViews$category %in% top10, ]$publish_time,"%M"), mostViews[mostViews$category %in% top10, ]$category) %>% as.data.frame.matrix %>% d3heatmap(F,F,col=colorRamp(c('seagreen','lightyellow','red')))
table(format(mostViews[mostViews$category %in% top10, ]$publish_time,"%w"), mostViews[mostViews$category %in% top10, ]$category) %>% as.data.frame.matrix %>% d3heatmap(F,F,col=colorRamp(c('seagreen','lightyellow','red')))
table(format(mostViews[mostViews$category %in% top10, ]$publish_time,"%H"), mostViews[mostViews$category %in% top10, ]$category) %>% as.data.frame.matrix %>% d3heatmap(F,F,col=colorRamp(c('seagreen','lightyellow','red')))
=======
# 什麼類型的影片觀眾參與度最高(喜歡數 + 觀看數 + 評論數) : Music、Entertainment、Comedy、People & Blogs、Howto & Style
group_by(mostViews, category) %>% summarise(engagement = sum(likes + views + comment_count)) %>% arrange(desc(engagement)) %>% ggplot(aes(x = reorder(category, engagement), y = engagement, fill = category)) + geom_bar(stat = "identity") + coord_flip()
>>>>>>> e50799ed3674f58db3b9bed46343315bd2e70f0d
